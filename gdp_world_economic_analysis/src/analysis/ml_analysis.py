# -*- coding: utf-8 -*-
"""
GDP World Economic Analysis - Machine Learning Analysis
=======================================================

Este m√≥dulo aplica t√©cnicas de Machine Learning para clustering de econom√≠as,
clasificaci√≥n y an√°lisis predictivo.

Autor: Kevin
Fecha: Septiembre 2025
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots

# Machine Learning libraries
from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.decomposition import PCA
from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import classification_report, silhouette_score, adjusted_rand_score
from sklearn.linear_model import LinearRegression, Ridge
from sklearn.svm import SVR

import warnings
warnings.filterwarnings('ignore')

class EconomicMLAnalyzer:
    """Clase para an√°lisis de Machine Learning en datos econ√≥micos"""
    
    def __init__(self, df):
        """
        Inicializa el analizador ML
        
        Args:
            df (pd.DataFrame): DataFrame con datos de PIB
        """
        self.df = df.copy()
        self.years = [col for col in df.columns if col.isdigit()]
        self._prepare_features()
        
    def _prepare_features(self):
        """Prepara caracter√≠sticas para ML"""
        print("üîß Preparando caracter√≠sticas para Machine Learning...")
        
        # Convertir a numeric
        for year in self.years:
            self.df[year] = pd.to_numeric(self.df[year], errors='coerce')
        
        # Crear caracter√≠sticas econ√≥micas
        self.features_df = self.df.copy()
        
        # 1. PIB promedio
        gdp_cols = [col for col in self.years if col in self.df.columns]
        self.features_df['GDP_Mean'] = self.df[gdp_cols].mean(axis=1, skipna=True)
        
        # 2. PIB mediano
        self.features_df['GDP_Median'] = self.df[gdp_cols].median(axis=1, skipna=True)
        
        # 3. Volatilidad (desviaci√≥n est√°ndar)
        self.features_df['GDP_Std'] = self.df[gdp_cols].std(axis=1, skipna=True)
        
        # 4. Coeficiente de variaci√≥n
        self.features_df['GDP_CV'] = (self.features_df['GDP_Std'] / self.features_df['GDP_Mean']) * 100
        
        # 5. Tasa de crecimiento total
        if len(gdp_cols) >= 2:
            first_year = gdp_cols[0]
            last_year = gdp_cols[-1]
            
            self.features_df['Total_Growth'] = (
                (self.df[last_year] - self.df[first_year]) / self.df[first_year] * 100
            )
            
            # 6. CAGR (Compound Annual Growth Rate)
            years_diff = int(last_year) - int(first_year)
            self.features_df['CAGR'] = (
                ((self.df[last_year] / self.df[first_year]) ** (1/years_diff) - 1) * 100
            )
        
        # 7. PIB m√°s reciente
        latest_year = max(self.years)
        self.features_df['GDP_Latest'] = self.df[latest_year]
        
        # 8. Tendencia (usando regresi√≥n lineal simple)
        trend_slopes = []
        for idx, row in self.df.iterrows():
            gdp_values = []
            years_numeric = []
            
            for year in self.years:
                if pd.notna(row[year]):
                    gdp_values.append(row[year])
                    years_numeric.append(int(year))
            
            if len(gdp_values) >= 3:
                # Regresi√≥n lineal simple
                X = np.array(years_numeric).reshape(-1, 1)
                y = np.array(gdp_values)
                
                from sklearn.linear_model import LinearRegression
                lr = LinearRegression()
                lr.fit(X, y)
                trend_slopes.append(lr.coef_[0])
            else:
                trend_slopes.append(np.nan)
        
        self.features_df['Trend_Slope'] = trend_slopes
        
        # Limpiar datos faltantes
        self.features_df = self.features_df.dropna(subset=[
            'GDP_Mean', 'GDP_Std', 'Total_Growth', 'CAGR', 'GDP_Latest'
        ])
        
        print(f"‚úÖ Caracter√≠sticas preparadas para {len(self.features_df)} pa√≠ses")
        
    def perform_clustering_analysis(self, n_clusters=5):
        """Realiza an√°lisis de clustering de econom√≠as"""
        print("üéØ Realizando an√°lisis de clustering...")
        
        # Seleccionar caracter√≠sticas para clustering
        feature_cols = ['GDP_Mean', 'GDP_Std', 'CAGR', 'GDP_Latest']
        X = self.features_df[feature_cols].copy()
        
        # Normalizar datos
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X)
        
        # 1. K-Means Clustering
        print(f"üîç Aplicando K-Means con {n_clusters} clusters...")
        
        kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
        self.features_df['KMeans_Cluster'] = kmeans.fit_predict(X_scaled)
        
        # Calcular silhouette score
        silhouette_avg = silhouette_score(X_scaled, self.features_df['KMeans_Cluster'])
        print(f"üìä Silhouette Score K-Means: {silhouette_avg:.3f}")
        
        # 2. Clustering Jer√°rquico
        print("üå≥ Aplicando Clustering Jer√°rquico...")
        
        hierarchical = AgglomerativeClustering(n_clusters=n_clusters)
        self.features_df['Hierarchical_Cluster'] = hierarchical.fit_predict(X_scaled)
        
        # 3. PCA para visualizaci√≥n
        pca = PCA(n_components=2)
        X_pca = pca.fit_transform(X_scaled)
        
        self.features_df['PCA1'] = X_pca[:, 0]
        self.features_df['PCA2'] = X_pca[:, 1]
        
        # Crear visualizaciones
        fig = make_subplots(
            rows=1, cols=2,
            subplot_titles=('K-Means Clustering', 'Clustering Jer√°rquico'),
            specs=[[{"secondary_y": False}, {"secondary_y": False}]]
        )
        
        colors = px.colors.qualitative.Set1
        
        # K-Means plot
        for i in range(n_clusters):
            cluster_data = self.features_df[self.features_df['KMeans_Cluster'] == i]
            
            fig.add_trace(
                go.Scatter(
                    x=cluster_data['PCA1'],
                    y=cluster_data['PCA2'],
                    mode='markers',
                    name=f'K-Means Cluster {i}',
                    text=cluster_data['Country'],
                    hovertemplate='<b>%{text}</b><br>' +
                                'PCA1: %{x:.2f}<br>' +
                                'PCA2: %{y:.2f}<br>' +
                                '<extra></extra>',
                    marker=dict(
                        color=colors[i % len(colors)],
                        size=8,
                        opacity=0.7
                    ),
                    showlegend=True
                ),
                row=1, col=1
            )
        
        # Hierarchical plot
        for i in range(n_clusters):
            cluster_data = self.features_df[self.features_df['Hierarchical_Cluster'] == i]
            
            fig.add_trace(
                go.Scatter(
                    x=cluster_data['PCA1'],
                    y=cluster_data['PCA2'],
                    mode='markers',
                    name=f'Jer√°rquico Cluster {i}',
                    text=cluster_data['Country'],
                    hovertemplate='<b>%{text}</b><br>' +
                                'PCA1: %{x:.2f}<br>' +
                                'PCA2: %{y:.2f}<br>' +
                                '<extra></extra>',
                    marker=dict(
                        color=colors[i % len(colors)],
                        size=8,
                        opacity=0.7,
                        symbol='diamond'
                    ),
                    showlegend=True
                ),
                row=1, col=2
            )
        
        fig.update_layout(
            title={
                'text': "üéØ Clustering de Econom√≠as Mundiales",
                'x': 0.5,
                'xanchor': 'center',
                'font': {'size': 20}
            },
            height=600,
            width=1400,
            template='plotly_white'
        )
        
        # An√°lisis de clusters
        self._analyze_clusters()
        
        return fig
    
    def _analyze_clusters(self):
        """Analiza las caracter√≠sticas de cada cluster"""
        print("\n" + "="*60)
        print("üìä AN√ÅLISIS DE CLUSTERS ECON√ìMICOS")
        print("="*60)
        
        for cluster in sorted(self.features_df['KMeans_Cluster'].unique()):
            cluster_data = self.features_df[self.features_df['KMeans_Cluster'] == cluster]
            
            print(f"\nüéØ CLUSTER {cluster} ({len(cluster_data)} pa√≠ses):")
            print("-" * 40)
            
            # Pa√≠ses en el cluster
            countries = cluster_data['Country'].tolist()
            print(f"üåç Pa√≠ses: {', '.join(countries[:5])}" + 
                  (f" y {len(countries)-5} m√°s" if len(countries) > 5 else ""))
            
            # Caracter√≠sticas promedio
            print(f"üí∞ PIB promedio: ${cluster_data['GDP_Mean'].mean()/1000:.1f}B")
            print(f"üìà CAGR promedio: {cluster_data['CAGR'].mean():.1f}%")
            print(f"üìä Volatilidad promedio: {cluster_data['GDP_Std'].mean()/1000:.1f}B")
            
            # Clasificar tipo de econom√≠a
            avg_gdp = cluster_data['GDP_Mean'].mean()
            avg_growth = cluster_data['CAGR'].mean()
            
            if avg_gdp > 1000000:  # > 1T
                economy_type = "üíé Econom√≠as Grandes"
            elif avg_gdp > 100000:  # > 100B
                economy_type = "üè≠ Econom√≠as Medianas"
            else:
                economy_type = "üå± Econom√≠as Peque√±as"
            
            if avg_growth > 10:
                growth_type = "üöÄ Alto Crecimiento"
            elif avg_growth > 3:
                growth_type = "üìà Crecimiento Moderado"
            else:
                growth_type = "üêå Crecimiento Lento"
            
            print(f"üè∑Ô∏è  Tipo: {economy_type} - {growth_type}")
    
    def classify_economy_development(self):
        """Clasifica econom√≠as como desarrolladas/emergentes usando ML"""
        print("üéì Clasificando econom√≠as: Desarrolladas vs Emergentes...")
        
        # Clasificaci√≥n manual inicial para entrenamiento
        # (Esta es una simplificaci√≥n - en la realidad usar√≠amos datos m√°s robustos)
        developed_countries = [
            'United States', 'Germany', 'Japan', 'United Kingdom', 'France',
            'Italy', 'Canada', 'South Korea', 'Australia', 'Spain',
            'Netherlands', 'Switzerland', 'Belgium', 'Austria', 'Sweden',
            'Norway', 'Denmark', 'Finland', 'Ireland', 'New Zealand'
        ]
        
        # Crear etiquetas
        self.features_df['Development_Level'] = self.features_df['Country'].apply(
            lambda x: 'Desarrollada' if x in developed_countries else 'Emergente'
        )
        
        # Preparar datos para entrenamiento
        feature_cols = ['GDP_Mean', 'GDP_Latest', 'CAGR', 'GDP_Std', 'Total_Growth']
        X = self.features_df[feature_cols]
        y = self.features_df['Development_Level']
        
        # Dividir datos
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.3, random_state=42, stratify=y
        )
        
        # Normalizar
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)
        
        # Entrenar Random Forest
        rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)
        rf_classifier.fit(X_train_scaled, y_train)
        
        # Predicciones
        y_pred = rf_classifier.predict(X_test_scaled)
        
        # Evaluaci√≥n
        accuracy = rf_classifier.score(X_test_scaled, y_test)
        print(f"üìä Precisi√≥n del modelo: {accuracy:.3f}")
        
        # Cross-validation
        cv_scores = cross_val_score(rf_classifier, X_train_scaled, y_train, cv=5)
        print(f"üéØ Cross-validation score: {cv_scores.mean():.3f} ¬± {cv_scores.std():.3f}")
        
        # Importancia de caracter√≠sticas
        feature_importance = pd.DataFrame({
            'Feature': feature_cols,
            'Importance': rf_classifier.feature_importances_
        }).sort_values('Importance', ascending=False)
        
        print(f"\nüìà Importancia de caracter√≠sticas:")
        for _, row in feature_importance.iterrows():
            print(f"   {row['Feature']}: {row['Importance']:.3f}")
        
        # Visualizaci√≥n de importancia
        fig = px.bar(
            feature_importance,
            x='Importance',
            y='Feature',
            orientation='h',
            title="üìà Importancia de Caracter√≠sticas para Clasificaci√≥n",
            labels={'Importance': 'Importancia', 'Feature': 'Caracter√≠stica'}
        )
        
        fig.update_layout(
            height=400,
            width=800,
            template='plotly_white'
        )
        
        return rf_classifier, scaler, fig
    
    def predict_future_gdp(self, target_year=2028):
        """Predice PIB futuro usando ML"""
        print(f"üîÆ Prediciendo PIB para {target_year} usando Machine Learning...")
        
        # Preparar datos para entrenamiento
        # Usar a√±os como caracter√≠sticas y PIB como target
        feature_cols = ['GDP_Mean', 'CAGR', 'Trend_Slope', 'Total_Growth']
        X = self.features_df[feature_cols].copy()
        
        # Target: PIB del √∫ltimo a√±o disponible
        latest_year = max(self.years)
        y = self.features_df['GDP_Latest'].copy()
        
        # Dividir datos
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42
        )
        
        # Normalizar
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)
        
        # Entrenar m√∫ltiples modelos
        models = {
            'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42),
            'Ridge Regression': Ridge(alpha=1.0),
            'Support Vector Regression': SVR(kernel='rbf', C=1.0)
        }
        
        best_model = None
        best_score = -float('inf')
        best_name = ""
        
        print("\nüéØ Evaluando modelos:")
        for name, model in models.items():
            model.fit(X_train_scaled, y_train)
            score = model.score(X_test_scaled, y_test)
            print(f"   {name}: R¬≤ = {score:.3f}")
            
            if score > best_score:
                best_score = score
                best_model = model
                best_name = name
        
        print(f"\nüèÜ Mejor modelo: {best_name} (R¬≤ = {best_score:.3f})")
        
        # Predicciones para todos los pa√≠ses
        X_all_scaled = scaler.transform(X)
        predictions = best_model.predict(X_all_scaled)
        
        # Aplicar factor de crecimiento para el a√±o objetivo
        years_to_predict = target_year - int(latest_year)
        
        # Usar CAGR para proyectar al futuro
        future_predictions = []
        for i, (_, row) in enumerate(self.features_df.iterrows()):
            current_gdp = predictions[i]
            cagr = row['CAGR'] / 100  # Convertir a decimal
            
            # Aplicar crecimiento compuesto
            future_gdp = current_gdp * ((1 + cagr) ** years_to_predict)
            future_predictions.append(future_gdp)
        
        self.features_df[f'GDP_Predicted_{target_year}'] = future_predictions
        
        # Crear visualizaci√≥n de top predicciones
        top_predictions = self.features_df.nlargest(15, f'GDP_Predicted_{target_year}')
        
        fig = go.Figure()
        
        fig.add_trace(go.Bar(
            x=top_predictions[f'GDP_Predicted_{target_year}'] / 1000,
            y=top_predictions['Country'],
            orientation='h',
            marker=dict(
                color=top_predictions[f'GDP_Predicted_{target_year}'],
                colorscale='Viridis',
                showscale=True,
                colorbar=dict(title="PIB Predicho (Billones)")
            ),
            text=[f'${x/1000:.1f}B' for x in top_predictions[f'GDP_Predicted_{target_year}']],
            textposition='inside'
        ))
        
        fig.update_layout(
            title={
                'text': f"üîÆ Predicciones PIB para {target_year} - Top 15 Econom√≠as",
                'x': 0.5,
                'xanchor': 'center',
                'font': {'size': 20}
            },
            xaxis_title="PIB Predicho (Billones USD)",
            yaxis_title="Pa√≠s",
            height=600,
            width=1000,
            template='plotly_white'
        )
        
        print(f"\nüéØ TOP 5 PREDICCIONES PIB {target_year}:")
        for i, (_, row) in enumerate(top_predictions.head().iterrows(), 1):
            gdp_pred = row[f'GDP_Predicted_{target_year}'] / 1000
            print(f"   {i}. {row['Country']}: ${gdp_pred:.1f}B")
        
        return best_model, scaler, fig


def load_gdp_data():
    """Carga los datos de PIB"""
    import kagglehub
    import os
    
    path = kagglehub.dataset_download("codebynadiia/gdp-per-country-20202025")
    csv_file = os.path.join(path, "2020-2025.csv")
    return pd.read_csv(csv_file)


def main():
    """Funci√≥n principal para an√°lisis ML"""
    print("ü§ñ INICIANDO AN√ÅLISIS DE MACHINE LEARNING")
    print("="*60)
    
    # Cargar datos
    df = load_gdp_data()
    print(f"üìä Datos cargados: {df.shape[0]} pa√≠ses")
    
    # Crear analizador ML
    analyzer = EconomicMLAnalyzer(df)
    
    # 1. Clustering Analysis
    print("\n1Ô∏è‚É£ AN√ÅLISIS DE CLUSTERING")
    clustering_fig = analyzer.perform_clustering_analysis(n_clusters=5)
    
    # 2. Classification Analysis
    print("\n2Ô∏è‚É£ CLASIFICACI√ìN DE ECONOM√çAS")
    classifier, clf_scaler, importance_fig = analyzer.classify_economy_development()
    
    # 3. GDP Prediction
    print("\n3Ô∏è‚É£ PREDICCI√ìN DE PIB")
    predictor, pred_scaler, prediction_fig = analyzer.predict_future_gdp(target_year=2028)
    
    # Guardar resultados
    output_dir = "reports/figures/"
    import os
    os.makedirs(output_dir, exist_ok=True)
    
    # Guardar visualizaciones
    clustering_fig.write_html(f"{output_dir}ml_clustering_analysis.html")
    print(f"üíæ Guardado: {output_dir}ml_clustering_analysis.html")
    
    importance_fig.write_html(f"{output_dir}ml_feature_importance.html")
    print(f"üíæ Guardado: {output_dir}ml_feature_importance.html")
    
    prediction_fig.write_html(f"{output_dir}ml_gdp_predictions_2028.html")
    print(f"üíæ Guardado: {output_dir}ml_gdp_predictions_2028.html")
    
    print(f"\n" + "="*60)
    print("‚úÖ AN√ÅLISIS DE MACHINE LEARNING COMPLETADO")
    print("üéØ 3 modelos entrenados exitosamente")
    print("üìä 3 visualizaciones guardadas")
    print("üîú Siguiente: Dashboard Interactivo Final")

if __name__ == "__main__":
    main()